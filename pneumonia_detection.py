# -*- coding: utf-8 -*-
"""Pneumonia-Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cDEgPGzGZxt19vXQuNH4R3Azhbs66TxH

#Pneumonia-Detection

##Imports
"""

!pip install -q -U tensorflow_hub
!pip install -q tf-nightly-gpu
from __future__ import absolute_import, division, print_function, unicode_literals

import matplotlib.pylab as plt

import tensorflow as tf

tf.enable_eager_execution()

import tensorflow_hub as hub

from tensorflow.keras import layers

AUTOTUNE = tf.data.experimental.AUTOTUNE

"""## Download Kaggle dataset
Use Kaggle : "https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia"
"""

!mkdir .kaggle

import json
token = {"username":"levinsonophir","key":"ADD-YOUR-KEY-HERE"}
with open('/content/.kaggle/kaggle.json', 'w') as file:
    json.dump(token, file)

!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json

!chmod 600 /root/.kaggle/kaggle.json

!kaggle config set -n path -v /content

!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia

!cd /content/datasets/paultimothymooney/chest-xray-pneumonia && unzip *.zip

!cd /content/datasets/paultimothymooney/chest-xray-pneumonia && unzip chest_xray.zip

!cd /content/datasets/paultimothymooney/chest-xray-pneumonia/chest_xray/train && ls -l

!rmdir /content/datasets/paultimothymooney/chest-xray-pneumonia/chest_xray/test/.DS_Store
!rmdir /content/datasets/paultimothymooney/chest-xray-pneumonia/chest_xray/test/NORMAL/.DS_Store
!rmdir /content/datasets/paultimothymooney/chest-xray-pneumonia/chest_xray/test/PNEUMONIA/.DS_Store

!rmdir /content/datasets/paultimothymooney/chest-xray-pneumonia/chest_xray/train/.DS_Store
!rmdir /content/datasets/paultimothymooney/chest-xray-pneumonia/chest_xray/train/NORMAL/.DS_Store
!rmdir /content/datasets/paultimothymooney/chest-xray-pneumonia/chest_xray/train/PNEUMONIA/.DS_Store

!rmdir /content/datasets/paultimothymooney/chest-xray-pneumonia/chest_xray/val/.DS_Store
!rmdir /content/datasets/paultimothymooney/chest-xray-pneumonia/chest_xray/val/NORMAL/.DS_Store
!rmdir /content/datasets/paultimothymooney/chest-xray-pneumonia/chest_xray/val/PNEUMONIA/.DS_Store

!ls /content/datasets/paultimothymooney/chest-xray-pneumonia/chest_xray/test/NORMAL/.DS_Store

"""#Preprocessing

1. Build a function to return paths of all test, train and validation images
2. Create 'all_image_paths_test_pneumonia'
"""

import pathlib
import IPython.display as display
import random
import matplotlib.pyplot as plt

DATA_ROOT= '/content/datasets/paultimothymooney/chest-xray-pneumonia/chest_xray'

"""The following function retrieves the path off the shuffles paths and label for each type (type=train, test, val)"""

def get_paths_of_(path_type):
  data_root = pathlib.Path(DATA_ROOT + '/' + path_type)
  all_image_paths = list(data_root.glob('*/*.jpeg'))
  all_image_paths = [str(path) for path in all_image_paths]
  random.shuffle(all_image_paths)
  
  label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())
  
  label_to_index = dict((name, index) for index,name in enumerate(label_names))

  all_image_labels = [label_to_index[pathlib.Path(path).parent.name]
                    for path in all_image_paths]
  print("Size of {0} paths - {1}".format(path_type, len(all_image_paths)))
  return all_image_paths, all_image_labels

paths_train, image_labels_train = get_paths_of_('train')
paths_test,  image_labels_test  = get_paths_of_('test')
paths_val,   image_labels_val   = get_paths_of_('val')

label_names = sorted(item.name for item in pathlib.Path(DATA_ROOT+'/train').glob('*/') if item.is_dir())
print(label_names)

"""Load and format the images"""

def preprocess_image(image):
  image = tf.image.decode_jpeg(image, channels=3)
  image = tf.image.resize(image, [224, 224])
  image /= 255.0  # normalize to [0,1] range
  image.shape
  return image

def load_and_preprocess_image(path):
  image = tf.read_file(path)
  return preprocess_image(image)

img_path = paths_train[0]
img_raw = load_and_preprocess_image(img_path)

def showImage(image_path,label_path ,index):
  img_path = image_path[index]
  plt.imshow(load_and_preprocess_image(img_path))
  plt.grid(False)
  plt.title(label_names[label_path[index]].title())

showImage(paths_train,image_labels_train,8)

"""Build a tf.data.Dataset"""

train_path_ds = tf.data.Dataset.from_tensor_slices(paths_train)
train_image_ds = train_path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)
train_label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(image_labels_train, tf.int64))
train_image_label_ds = tf.data.Dataset.zip((train_image_ds, train_label_ds))


val_path_ds = tf.data.Dataset.from_tensor_slices(paths_val)
val_image_ds = val_path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)
val_label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(image_labels_val, tf.int64))
val_image_label_ds = tf.data.Dataset.zip((val_image_ds, val_label_ds))

test_test_ds = tf.data.Dataset.from_tensor_slices(paths_test)
test_image_ds = test_test_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)
test_label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(image_labels_test, tf.int64))
test_image_label_ds = tf.data.Dataset.zip((test_image_ds, test_label_ds))

print(train_image_label_ds)
print(train_image_ds)

ds = tf.data.Dataset.from_tensor_slices((paths_train, image_labels_train))

# The tuples are unpacked into the positional arguments of the mapped function
def load_and_preprocess_from_path_label(path, label):
  return load_and_preprocess_image(path), label

train_image_label_ds = ds.map(load_and_preprocess_from_path_label)
train_image_label_ds

"""# Download classifier
Using the 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2' mobilenet_v2 classifer. 
We try it with a sample image from our dataset (first validation image) and its results to : 'trilobite'
"""

classifier_url ="https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2" #@param {type:"string"}
IMAGE_SHAPE = (224, 224)

classifier = tf.keras.Sequential([
    hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))
])

image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)
image_data = image_generator.flow_from_directory(str('/content/datasets/paultimothymooney/chest-xray-pneumonia/chest_xray/train'), target_size=IMAGE_SHAPE)

for image_batch, label_batch in image_data:
  print("Image batch shape: ", image_batch.shape)
  print("Label batch shape: ", label_batch.shape)
  break

result_batch = classifier.predict(image_batch)
result_batch.shape

"""Update classifier with transfer learning: 
1. Download headless model from 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2'.
2. Create the module, and check the expected image size
3. Freeze the variables in the feature extractor layer, so that the training only modifies the new classifier layer.
4. Attach a classification head (with classification of 2 classes)
"""

feature_extractor_url = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2" #@param {type:"string"}

feature_extractor_layer = hub.KerasLayer(feature_extractor_url,input_shape=(224,224,3))

feature_extractor_layer.trainable = False

model = tf.keras.Sequential([
  feature_extractor_layer,
  layers.Dense(2, activation='softmax')
])

model.summary()

predictions = model(image_batch)
predictions.shape

"""# Training the model"""

model.compile(
  optimizer=tf.keras.optimizers.Adam(),
  loss='categorical_crossentropy',
  metrics=['acc'])

class CollectBatchStats(tf.keras.callbacks.Callback):
  def __init__(self):
    self.batch_losses = []
    self.batch_acc = []

  def on_train_batch_end(self, batch, logs=None):
    self.batch_losses.append(logs['loss'])
    self.batch_acc.append(logs['acc'])
    self.model.reset_metrics()

import numpy as np

steps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)
print(steps_per_epoch)

batch_stats_callback = CollectBatchStats()

history = model.fit(image_data, epochs=2,
                    steps_per_epoch=steps_per_epoch,
                    callbacks = [batch_stats_callback])

plt.figure()
plt.ylabel("Loss")
plt.xlabel("Training Steps")
plt.ylim([0,2])
plt.plot(batch_stats_callback.batch_losses)

plt.figure()
plt.ylabel("Accuracy")
plt.xlabel("Training Steps")
plt.ylim([0,1])
plt.plot(batch_stats_callback.batch_acc)

class_names = sorted(image_data.class_indices.items(), key=lambda pair:pair[1])
class_names = np.array([key.title() for key, value in class_names])
class_names

image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)
test_data = image_generator.flow_from_directory(str('/content/datasets/paultimothymooney/chest-xray-pneumonia/chest_xray/test'), target_size=IMAGE_SHAPE)
for test_batch, test_label_batch in test_data:
  print("Image batch shape: ", test_batch.shape)
  print("Label batch shape: ", test_label_batch.shape)
  break

predicted_batch = model.predict(test_batch)
predicted_id = np.argmax(predicted_batch, axis=-1)
predicted_label_batch = class_names[predicted_id]

label_id = np.argmax(test_label_batch, axis=-1)

plt.figure(figsize=(10,9))
plt.subplots_adjust(hspace=0.5)
for n in range(30):
  plt.subplot(6,5,n+1)
  plt.imshow(image_batch[n])
  color = "green" if predicted_id[n] == label_id[n] else "red"
  plt.title(predicted_label_batch[n].title(), color=color)
  plt.axis('off')
_ = plt.suptitle("Model predictions (green: correct, red: incorrect)")